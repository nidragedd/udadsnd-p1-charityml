{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Load the Census dataset\n",
    "data = pd.read_csv(\"census.csv\")\n",
    "data_test = pd.read_csv(\"test_census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education_level', 'education-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there any missing values in the dataset ?\n",
    "data_test.columns[data_test.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0          0\n",
       "age                17\n",
       "workclass          22\n",
       "education_level    20\n",
       "education-num      14\n",
       "marital-status     21\n",
       "occupation         22\n",
       "relationship       16\n",
       "race               19\n",
       "sex                19\n",
       "capital-gain       15\n",
       "capital-loss       17\n",
       "hours-per-week     13\n",
       "native-country     16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OK...almost everywhere, how many per feature ?\n",
    "# Are there any missing values in the dataset ?\n",
    "data_test.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age_per_country_sex_edlvl = data.groupby(['native-country', 'sex', 'education-num']).age.mean().reset_index()\n",
    "wk_per_country_sex_edlvl = data.groupby(['native-country', 'sex', 'education-num', 'workclass']).income.count().reset_index()\n",
    "education_table = data.groupby(['education-num', 'education_level']).income.count().reset_index()\n",
    "sex_age_marital = data.groupby(['sex', 'age', 'marital-status']).income.count().reset_index()\n",
    "occupation_per_edlvl = data.groupby(['occupation','education-num', 'education_level']).income.count().reset_index()\n",
    "workload = data.groupby(['education-num'])['hours-per-week'].mean().reset_index()\n",
    "#age_per_country_sex_edlvl.tail(10)\n",
    "#wk_per_country_sex_edlvl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacement strategy for missing values\n",
    "def _replace_missing(row):\n",
    "    # Replace 'age' by the mean of people having the same native-country, sex and education level. Why ? Why not ?\n",
    "    if pd.isnull(row.age):\n",
    "        val = age_per_country_sex_edlvl[\n",
    "                (age_per_country_sex_edlvl['sex'] == row.sex)\n",
    "                & (age_per_country_sex_edlvl['native-country'] == row['native-country'])\n",
    "                & (age_per_country_sex_edlvl['education-num'] == row['education-num'])]\n",
    "        row.age = val.age.sum()\n",
    "    \n",
    "    if pd.isnull(row.workclass):\n",
    "        val = wk_per_country_sex_edlvl[\n",
    "                (wk_per_country_sex_edlvl['sex'] == row.sex)\n",
    "                & (wk_per_country_sex_edlvl['native-country'] == row['native-country'])\n",
    "                & (wk_per_country_sex_edlvl['education-num'] == row['education-num'])].sort_values(by='income', ascending=False)\n",
    "        row.workclass = val[:1].workclass.unique()[0]\n",
    "    \n",
    "    if pd.isnull(row.education_level):\n",
    "        val = education_table[education_table['education-num'] == row['education-num']]\n",
    "        row.education_level = val.education_level.unique()[0]\n",
    "    \n",
    "    if pd.isnull(row['education-num']):\n",
    "        val = education_table[education_table.education_level == row.education_level]\n",
    "        row['education-num'] = val['education-num'].unique()[0]\n",
    "    \n",
    "    if pd.isnull(row['marital-status']):\n",
    "        val = sex_age_marital[(sex_age_marital.sex == row.sex)\n",
    "                             & (sex_age_marital.age == row.age)].sort_values(by='income', ascending=False)\n",
    "        row['marital-status'] = val[:1]['marital-status'].unique()[0]\n",
    "    \n",
    "    if pd.isnull(row.occupation):\n",
    "        val = occupation_per_edlvl[(occupation_per_edlvl['education-num'] == row['education-num'])\n",
    "                                  & (occupation_per_edlvl['education_level'] == row['education_level'])].sort_values(by='income', ascending=False)\n",
    "        row.occupation = val[:1].occupation.unique()[0]\n",
    "    \n",
    "    if pd.isnull(row.relationship):\n",
    "        if row['marital-status'] == ' Married-civ-spouse':\n",
    "            if row['sex'] == ' Female':\n",
    "                row.relationship = ' Wife'\n",
    "            if row['sex'] == ' Male':\n",
    "                row.relationship = ' Husband'\n",
    "        elif row['marital-status'] in [' Married-spouse-absent', ' Never-married', ' Divorced', ' Separated', ' Widowed', ' Married-AF-spouse']:\n",
    "            row.relationship = ' Not-in-family'\n",
    "    \n",
    "    if pd.isnull(row.race):\n",
    "        row.race = ' White' # the most common value, moreover for USA which is the value of native-country for missing 'race' rows\n",
    "    \n",
    "    if pd.isnull(row.sex):\n",
    "        if row.relationship == ' Wife':\n",
    "            row.sex = ' Female'\n",
    "        else:\n",
    "            row.sex = ' Male'\n",
    "            \n",
    "    if pd.isnull(row['capital-gain']):\n",
    "        row['capital-gain'] = 0.0\n",
    "    if pd.isnull(row['capital-loss']):\n",
    "        row['capital-loss'] = 0.0\n",
    "        \n",
    "    if pd.isnull(row['hours-per-week']):\n",
    "        val = workload[workload['education-num'] == row['education-num']]\n",
    "        row['hours-per-week'] = val['hours-per-week'].unique()[0]\n",
    "    \n",
    "    if pd.isnull(row['native-country']):\n",
    "        row['native-country'] = ' United-States'\n",
    "    \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply our great preprocessing phase to replace missing values with most common or most probable values\n",
    "data_test = data_test.apply(_replace_missing, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "age                0\n",
       "workclass          0\n",
       "education_level    0\n",
       "education-num      0\n",
       "marital-status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "sex                0\n",
       "capital-gain       0\n",
       "capital-loss       0\n",
       "hours-per-week     0\n",
       "native-country     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check it worked as expected\n",
    "data_test.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target label\n",
    "income_raw = data['income']\n",
    "features_raw = data.drop('income', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def preprocess_data(features_raw):\n",
    "    # Log-transform the skewed features\n",
    "    skewed = ['capital-gain', 'capital-loss']\n",
    "    numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "    \n",
    "    features_log_transformed = pd.DataFrame(data = features_raw)\n",
    "    features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n",
    "\n",
    "    scaler = MinMaxScaler() # default=(0, 1)\n",
    "    features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)\n",
    "    features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n",
    "\n",
    "    # One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()\n",
    "    features_final = pd.get_dummies(features_log_minmax_transform)\n",
    "    return features_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = preprocess_data(features_raw)\n",
    "features_test = preprocess_data(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 total features after one-hot encoding.\n"
     ]
    }
   ],
   "source": [
    "# Encode the 'income_raw' data to numerical values\n",
    "income = income_raw.map({'<=50K':0, '>50K':1})\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(features_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=5,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=400,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1, tol=0.0001, validation_fraction=0.1, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "                           max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=5,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=400,\n",
    "                           n_iter_no_change=None, presort='auto',\n",
    "                           random_state=None, subsample=1, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False)\n",
    "\n",
    "clf.fit(features_final, income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prediction = features_test.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_prediction)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elements are (rows, columns): (45222, 2)\n"
     ]
    }
   ],
   "source": [
    "ts = f\"{datetime.datetime.now():%Y-%m-%d-%H%M%S}\"\n",
    "features_test['income'] = predictions\n",
    "features_test['id'] = features_test['Unnamed: 0']\n",
    "result_df = features_test[['id', 'income']]\n",
    "print(\"Total elements are (rows, columns): {}\".format(result_df.shape))\n",
    "result_df.to_csv('./submission-{}.csv'.format(ts), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
